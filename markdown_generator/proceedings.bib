@inproceedings{Sharifian2024,
  author          = {Sharifian, Hamed and Sojoodi, Amirhossein and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2024/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/A Topology- and Load-Aware Design for Neighborhood Allgather - Sharifian, Sojoodi, Afsahi - Proceedings of the IEEE Interna.pdf:pdf},
  keywords        = {MPI,Neighborhood{\_}Collectives},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {MPI,Neighborhood{\_}Collectives},
  pages           = {1--12},
  title           = {{A Topology- and Load-Aware Design for Neighborhood Allgather}},
  year            = {2024}
}
@inproceedings{Sojoodi2024,
  author        = {Sojoodi, Amirhossein and Temucin, Yıltan Hassan and Afsahi, Ahmad},
  booktitle     = {Proceedings of the International Workshop on Extreme Heterogeneity Solutions (ExHET)},
  doi           = {10.1145/3642961.3643800},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2024/Proceedings of the International Workshop on Extreme Heterogeneity Solutions (ExHET)/Enhancing Intra-Node GPU-to-GPU Performance in MPI UCX through Multi-Path Communication - Sojoodi, Temucin, Afsahi -.pdf:pdf},
  isbn          = {9798400705373},
  keywords      = {GPU,MPI,Multi-Path Communication,NVLink,P2P,PCIe,UCX,gpu,mpi,multi-path communica-,p2p,ucx},
  mendeley-tags = {GPU,MPI,UCX},
  pages         = {1--6},
  title         = {{Enhancing Intra-Node GPU-to-GPU Performance in MPI + UCX through Multi-Path Communication}},
  year          = {2024}
}
@article{Witte2022,
  abstract      = {Solving partial differential equations with deep learning makes it possible to reduce simulation times by multiple orders of magnitude and unlock scientific methods that typically rely on large numbers of sequential simulations, such as optimization and uncertainty quantification. Two of the largest challenges of adopting scientific AI for industrial problem settings is that training datasets must be simulated in advance and that neural networks for solving large-scale PDEs exceed the memory capabilities of current GPUs. We introduce a distributed programming API in the Julia language for simulating training data in parallel on the cloud and without requiring users to manage the underlying HPC infrastructure. In addition, we show that model-parallel deep learning based on domain decomposition allows us to scale neural networks for solving PDEs to commercial-scale problem settings and achieve above 90{\%} parallel efficiency. Combining our cloud API for training data generation and model-parallel deep learning, we train large-scale neural networks for solving the 3D Navier-Stokes equation and simulating 3D CO2 flow in porous media. For the CO2 example, we simulate a training dataset based on a commercial carbon capture and storage (CCS) project and train a neural network for CO2 flow simulation on a 3D grid with over 2 million cells that is 5 orders of magnitudes faster than a conventional numerical simulator and 3,200 times cheaper.},
  archiveprefix = {arXiv},
  arxivid       = {2211.12709},
  author        = {Witte, Philipp A. and Hewett, Russell J. and Saurabh, Kumar and Sojoodi, Amirhossein and Chandra, Ranveer},
  eprint        = {2211.12709},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/SciAI4Industry -- Solving PDEs for industry-scale problems with deep learning - Witte et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Deep{\_}Learning},
  mendeley-tags = {Deep{\_}Learning},
  pages         = {1--11},
  title         = {{SciAI4Industry -- Solving PDEs for industry-scale problems with deep learning}},
  url           = {https://arxiv.org/abs/2211.12709},
  year          = {2022}
}
@inproceedings{Alizadeh2022,
  abstract        = {MPI collective communication operations are used extensively in parallel applications. As such, researchers have been investigating how to improve their performance and scalability to directly impact application performance. Unfortunately, most of these studies are based on the premise that all processes arrive at the collective call simultaneously. A few studies though have shown that imbalanced Process Arrival Pattern (PAP) is ubiquitous in real environments, significantly affecting the collective performance. Therefore, devising PAP-aware collective algorithms that could improve performance, while challenging, is highly desirable. This paper is along those lines but in the context of Deep Learning (DL) workloads that have become maintstream. This paper presents a brief characterization of collective communications, in particular MPI-Allreduce, in the Horovod distributed Deep Learning framework and shows that the arrival pattern of MPI processes is indeed imbalanced. It then proposes an intra-node shared-memory PAP-aware MPI-Allreduce algorithm for small to medium messages, where the leader process is dynamically chosen based on the arrival time of the processes at each invocation of the collective call. We then propose an intra-node PAP-aware algorithm for large messages that dynamically constructs the reduction schedule at each MPI-Allreduce invocation. Finally, we propose a PAP-aware cluster-wide hierarchical algorithm, which is extended by utilizing our intra-node PAP-aware designs, that imposes less data dependency among processes given its hierarchical nature compared to flat algorithms. The proposed algorithms deliver up to 58{\%} and 17{\%} improvement at the micro-benchmark and Horovod with TensorFlow application over the native algorithms, respectively.},
  author          = {Alizadeh, Pedram and Sojoodi, Amirhossein and {Hassan Temucin}, Yiltan and Afsahi, Ahmad},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3555819.3555857},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Efficient Process Arrival Pattern Aware Collective Communication for Deep Learning - Alizadeh et al. - Proceedings of the European MPI U.pdf:pdf},
  isbn            = {9781450397995},
  keywords        = {Collective Communication,Deep{\_}Learning,Distributed Deep Learning,MPI,MPI-Allreduce,PAP,Process Arrival Pattern},
  mendeley-groups = {MustKnow,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,MPI,PAP},
  pages           = {68--78},
  title           = {{Efficient Process Arrival Pattern Aware Collective Communication for Deep Learning}},
  year            = {2022}
}
@article{Temuc2021b,
  author          = {Temucin, Yıltan Hassan and Sojoodi, Amirhossein and Alizadeh, Pedram and Kitor, Benjamin W and Afsahi, Ahmad},
  doi             = {10.1109/MM.2022.3148670},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Micro/Accelerating Deep Learning using Interconnect-Aware UCX Communication for MPI Collectives - Temucin et al. - IEEE Micro.pdf:pdf},
  journal         = {IEEE Micro},
  keywords        = {Deep{\_}Learning,GPU,MPI},
  mendeley-groups = {MustKnow,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI},
  pages           = {1--9},
  title           = {{Accelerating Deep Learning using Interconnect-Aware UCX Communication for MPI Collectives}},
  year            = {2021}
}
@inproceedings{Temucin2021,
  author          = {Temucin, Yıltan Hassan and Sojoodi, Amirhossein and Alizadeh, Pedram and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi             = {10.1109/HOTI52880.2021.00018},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Efficient Multi-Path NVLink PCIe-Aware UCX based Collective Communication for Deep Learning - Temucin et al. - Proceedings of t.pdf:pdf},
  keywords        = {-mpi,Deep{\_}Learning,GPU,MPI,UCX,collective communication,cuda,deep learning workloads,gpu,nvlink,ucx},
  mendeley-groups = {MustKnow,UsedInComp2,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,UCX},
  pages           = {1--10},
  title           = {{Efficient Multi-Path NVLink / PCIe-Aware UCX based Collective Communication for Deep Learning}},
  year            = {2021}
}
@article{Sojoodi2020,
  abstract      = {During recent years, big data explosion and the increase in main memory capacity, on the one hand, and the need for faster data processing, on the other hand, have caused the development of various in-memory processing tools to manage and analyze data. Engaging the speed of the main memory and advantaging data locality, these tools can process a large amount of data with high performance. Apache Ignite, as a distributed in-memory platform, can process massive volumes of data in parallel. Currently, this platform is CPU-based and does not utilize the GPU's processing resources. To address this concern, we introduce Ignite-GPU that uses the GPU's massively parallel processing power. Ignite-GPU handles a number of challenges in integrating GPUs into Ignite and utilizes the GPU's available resources. We have also identified and eliminated time-consuming overheads and used various GPU-specific optimization techniques to improve overall performance. Eventually, we have evaluated Ignite-GPU with the Genetic Algorithm, as a representative of data and compute-intensive algorithms, and gained more than thousands of times speedup in comparison with its CPU version.},
  author        = {Sojoodi, Amirhossein and {Salimi Beni}, Majid and Khunjush, Farshad},
  doi           = {10.1007/s11227-020-03390-z},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Journal of Supercomputing/Ignite-GPU a GPU-enabled in-memory computing architecture on clusters - Sojoodi, Salimi Beni, Khunjush - Journal of Supercomputing.pdf:pdf},
  isbn          = {1122702003390},
  issn          = {15730484},
  journal       = {Journal of Supercomputing},
  keywords      = {Apache Ignite,GPU,Genetic{\_}Algorithm,Ignite,In-memory computing,Parallel processing},
  mendeley-tags = {GPU,Genetic{\_}Algorithm,Ignite},
  pages         = {1--28},
  publisher     = {Springer US},
  title         = {{Ignite-GPU: a GPU-enabled in-memory computing architecture on clusters}},
  year          = {2020}
}
@inproceedings{SalimiBeni2020,
  abstract      = {Abstract—With the increasing rate of data generation in recent years, there is a need for modern tools to process these massive amounts of data. To that end, in-memory platforms are becoming increasingly popular, which can process high volumes of data at high speed and performance by utilizing Main Memory. Apache Ignite is one of the in-memory platforms that can process in parallel on multiple nodes. Although this platform provides many useful features, one of its limitations is the lack of utilizing the GPU's high processing power. Undoubtedly, using GPUs for operations that deal with heavy processing or high data volumes can be very beneficial, and significantly accelerate processing. One of the algorithms supported by Ignite is the Genetic Algorithm, which usually deals with large amounts of data, and might be very timeconsuming. In this paper, we have provided an extension for Ignite in which users can utilize GPUs to run their Genetic Algorithm applications. Also, we have used various GPUrelated optimization techniques to improve performance and finally evaluated our extension with three benchmarks. Our results proved the ease of use, and the high performance of the proposed work compared to Ignite.},
  author        = {{Salimi Beni}, Majid and Sojoodi, Amirhossein and Khunjush, Farshad},
  booktitle     = {Proceedings of the International Symposium on Computer Architecture and Digital Systems (CADS)},
  doi           = {10.1109/CADS50570.2020.9211857},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Symposium on Computer Architecture and Digital Systems (CADS)/A GPU-Enabled Extension for Apache Ignite to Facilitate Running Genetic Algorithms - Salimi Beni, Sojoodi, K.pdf:pdf},
  isbn          = {9781728181110},
  keywords      = {GPU,Genetic{\_}Algorithm,Ignite,apache ignite,gpu,in-memory computing},
  mendeley-tags = {GPU,Genetic{\_}Algorithm,Ignite},
  pages         = {1--8},
  title         = {{A GPU-Enabled Extension for Apache Ignite to Facilitate Running Genetic Algorithms}},
  year          = {2020}
}
